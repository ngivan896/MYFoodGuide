/**
 * ğŸœ NutriScan MY - Google Colab æ¨¡æ¿ç”Ÿæˆå™¨
 * åŠ¨æ€ç”ŸæˆåŒ…å«ç”¨æˆ·é…ç½®çš„è®­ç»ƒæ¨¡æ¿
 */

class ColabTemplateGenerator {
    constructor() {
        this.templateBase = this.getBaseTemplate();
    }

    /**
     * ç”ŸæˆåŒ…å«ç”¨æˆ·é…ç½®çš„Colabæ¨¡æ¿
     */
    generateTemplate(trainingConfig) {
        const config = {
            model_type: trainingConfig.model_type || 'yolov8n',
            epochs: trainingConfig.epochs || 100,
            batch_size: trainingConfig.batch_size || 16,
            learning_rate: trainingConfig.learning_rate || 0.01,
            img_size: trainingConfig.img_size || 640,
            patience: trainingConfig.patience || 20,
            save_period: trainingConfig.save_period || 10,
            session_id: trainingConfig.session_id || this.generateSessionId(),
            dashboard_url: trainingConfig.dashboard_url || 'http://localhost:5000',
            dataset_id: trainingConfig.dataset_id || 'default_dataset',
            augment: trainingConfig.augment || true,
            optimizer: trainingConfig.optimizer || 'AdamW',
            loss_function: trainingConfig.loss_function || 'BCE'
        };

        // æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´é»˜è®¤å‚æ•°
        if (config.model_type === 'yolov8s') {
            config.batch_size = Math.min(config.batch_size, 12);
            config.learning_rate = Math.min(config.learning_rate, 0.005);
        } else if (config.model_type === 'yolov8m') {
            config.batch_size = Math.min(config.batch_size, 8);
            config.learning_rate = Math.min(config.learning_rate, 0.003);
        }

        return this.templateBase
            .replace(/{{MODEL_TYPE}}/g, config.model_type)
            .replace(/{{EPOCHS}}/g, config.epochs)
            .replace(/{{BATCH_SIZE}}/g, config.batch_size)
            .replace(/{{LEARNING_RATE}}/g, config.learning_rate)
            .replace(/{{IMG_SIZE}}/g, config.img_size)
            .replace(/{{PATIENCE}}/g, config.patience)
            .replace(/{{SAVE_PERIOD}}/g, config.save_period)
            .replace(/{{SESSION_ID}}/g, config.session_id)
            .replace(/{{DASHBOARD_URL}}/g, config.dashboard_url)
            .replace(/{{DATASET_ID}}/g, config.dataset_id)
            .replace(/{{AUGMENT}}/g, config.augment)
            .replace(/{{OPTIMIZER}}/g, config.optimizer)
            .replace(/{{LOSS_FUNCTION}}/g, config.loss_function);
    }

    /**
     * ç”Ÿæˆä¼šè¯ID
     */
    generateSessionId() {
        return 'session_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
    }

    /**
     * è·å–åŸºç¡€æ¨¡æ¿
     */
    getBaseTemplate() {
        return `{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nutriscan_header"
   },
   "source": [
    "# ğŸœ NutriScan MY - é©¬æ¥è¥¿äºšé£Ÿç‰©è¯†åˆ«æ¨¡å‹è®­ç»ƒ\\n",
    "\\n",
    "## ğŸ“‹ è®­ç»ƒé…ç½®\\n",
    "- **ä¼šè¯ID**: {{SESSION_ID}}\\n",
    "- **æ¨¡å‹ç±»å‹**: {{MODEL_TYPE}}\\n",
    "- **è®­ç»ƒè½®æ¬¡**: {{EPOCHS}}\\n",
    "- **æ‰¹æ¬¡å¤§å°**: {{BATCH_SIZE}}\\n",
    "- **å­¦ä¹ ç‡**: {{LEARNING_RATE}}\\n",
    "- **å›¾åƒå¤§å°**: {{IMG_SIZE}}\\n",
    "\\n",
    "---\\n",
    "\\n",
    "## ğŸš€ è‡ªåŠ¨é…ç½®å®Œæˆï¼Œç‚¹å‡»è¿è¡Œæ‰€æœ‰å•å…ƒæ ¼å¼€å§‹è®­ç»ƒï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# ğŸ”§ å®‰è£…ä¾èµ–åŒ…\\n",
    "!pip install ultralytics roboflow torch torchvision matplotlib seaborn pandas numpy google-generativeai requests --quiet\\n",
    "print("âœ… ä¾èµ–åŒ…å®‰è£…å®Œæˆï¼")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_libraries"
   },
   "outputs": [],
   "source": [
    "# ğŸ“š å¯¼å…¥åº“\\n",
    "import os\\n",
    "import json\\n",
    "import time\\n",
    "import requests\\n",
    "from datetime import datetime\\n",
    "import matplotlib.pyplot as plt\\n",
    "import seaborn as sns\\n",
    "import pandas as pd\\n",
    "import numpy as np\\n",
    "\\n",
    "# YOLOv8 å’Œ Roboflow\\n",
    "from ultralytics import YOLO\\n",
    "from roboflow import Roboflow\\n",
    "\\n",
    "# Google Generative AI (Gemini)\\n",
    "import google.generativeai as genai\\n",
    "\\n",
    "print("âœ… åº“å¯¼å…¥å®Œæˆï¼")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_parameters"
   },
   "outputs": [],
   "source": [
    "# âš™ï¸ é…ç½®å‚æ•° - æ¥è‡ªDashboard\\n",
    "SESSION_ID = "{{SESSION_ID}}"\n",
    "DASHBOARD_URL = "{{DASHBOARD_URL}}"\n",
    "\n",
    "# APIé…ç½®\n",
    "ROBOFLOW_API_KEY = "BwTemPbP39LHLFH4teds"\n",
    "ROBOFLOW_PROJECT_ID = "projects/326667818607"\n",
    "GEMINI_API_KEY = "AIzaSyAT6_BA42_EwFRDVgPKNV8A_w_E2llJVm8"\n",
    "\n",
    "# è®­ç»ƒé…ç½® - ä»Dashboardä¼ é€’\n",
    "TRAINING_CONFIG = {\n",
    "    "model_type": "{{MODEL_TYPE}}",\n",
    "    "epochs": {{EPOCHS}},\n",
    "    "batch_size": {{BATCH_SIZE}},\n",
    "    "learning_rate": {{LEARNING_RATE}},\n",
    "    "img_size": {{IMG_SIZE}},\n",
    "    "patience": {{PATIENCE}},\n",
    "    "save_period": {{SAVE_PERIOD}},\n",
    "    "augment": {{AUGMENT}},\n",
    "    "optimizer": "{{OPTIMIZER}}",\n",
    "    "loss_function": "{{LOSS_FUNCTION}}"\n",
    "}\n",
    "\n",
    "# è¾“å‡ºç›®å½•\n",
    "OUTPUT_DIR = f"/content/nutriscan_training_{SESSION_ID}"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# åˆ›å»ºæ—¥å¿—ç›®å½•\n",
    "LOG_DIR = os.path.join(OUTPUT_DIR, "logs")\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "print("âœ… é…ç½®å‚æ•°è®¾ç½®å®Œæˆï¼")\n",
    "print(f"ğŸ“Š è®­ç»ƒé…ç½®: {TRAINING_CONFIG}")\n",
    "print(f"ğŸ†” ä¼šè¯ID: {SESSION_ID}")\n",
    "print(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")\n",
    "\n",
    "# é€šçŸ¥Dashboardè®­ç»ƒå¼€å§‹\n",
    "try:\n",
    "    requests.post(f"{DASHBOARD_URL}/api/training/colab/status/{SESSION_ID}", \n",
    "                 json={"status": "started", "timestamp": datetime.now().isoformat(), "config": TRAINING_CONFIG})\n",
    "    print("âœ… å·²é€šçŸ¥Dashboardè®­ç»ƒå¼€å§‹")\n",
    "except:\n",
    "    print("âš ï¸ æ— æ³•è¿æ¥åˆ°Dashboardï¼Œç»§ç»­è®­ç»ƒ...")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_dataset"
   },
   "outputs": [],
   "source": [
    "# ğŸ“Š ä¸‹è½½Roboflowæ•°æ®é›†\n",
    "print("ğŸ”— è¿æ¥åˆ°Roboflowé¡¹ç›®...")\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "project = rf.workspace("malaysian-food-detection").project("malaysian-food-detection")\n",
    "dataset = project.version(1).download("yolov8")\n",
    "\n",
    "print(f"âœ… æ•°æ®é›†ä¸‹è½½å®Œæˆï¼")\n",
    "print(f"ğŸ“ æ•°æ®é›†è·¯å¾„: {dataset.location}")\n",
    "\n",
    "# ç»Ÿè®¡æ•°æ®é›†\n",
    "def count_files(directory):\n",
    "    if os.path.exists(directory):\n",
    "        images = len([f for f in os.listdir(directory) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        labels = len([f for f in os.listdir(directory) if f.endswith('.txt')])\n",
    "        return images, labels\n",
    "    return 0, 0\n",
    "\n",
    "train_path = os.path.join(dataset.location, "train")\n",
    "val_path = os.path.join(dataset.location, "valid")\n",
    "test_path = os.path.join(dataset.location, "test")\n",
    "\n",
    "train_images, train_labels = count_files(train_path)\n",
    "val_images, val_labels = count_files(val_path)\n",
    "test_images, test_labels = count_files(test_path)\n",
    "\n",
    "dataset_stats = {\n",
    "    "train_images": train_images,\n",
    "    "val_images": val_images,\n",
    "    "test_images": test_images,\n",
    "    "total_images": train_images + val_images + test_images\n",
    "}\n",
    "\n",
    "print("ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")\n",
    "print(f"  è®­ç»ƒé›†: {train_images} å¼ å›¾ç‰‡, {train_labels} ä¸ªæ ‡ç­¾æ–‡ä»¶")\n",
    "print(f"  éªŒè¯é›†: {val_images} å¼ å›¾ç‰‡, {val_labels} ä¸ªæ ‡ç­¾æ–‡ä»¶")\n",
    "print(f"  æµ‹è¯•é›†: {test_images} å¼ å›¾ç‰‡, {test_labels} ä¸ªæ ‡ç­¾æ–‡ä»¶")\n",
    "print(f"  æ€»è®¡: {dataset_stats['total_images']} å¼ å›¾ç‰‡")\n",
    "\n",
    "# é€šçŸ¥Dashboardæ•°æ®é›†ä¿¡æ¯\n",
    "try:\n",
    "    requests.post(f"{DASHBOARD_URL}/api/training/colab/status/{SESSION_ID}", \n",
    "                 json={"status": "dataset_ready", "dataset_stats": dataset_stats})\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "initialize_model"
   },
   "outputs": [],
   "source": [
    "# ğŸ¤– åˆå§‹åŒ–YOLOv8æ¨¡å‹\n",
    "print("ğŸ¤– åˆå§‹åŒ–YOLOv8æ¨¡å‹...")\n",
    "model_type = TRAINING_CONFIG["model_type"]\n",
    "model = YOLO(f"{model_type}.pt")\n",
    "\n",
    "print(f"âœ… YOLOv8æ¨¡å‹åˆå§‹åŒ–å®Œæˆ: {model_type}")\n",
    "print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.model.parameters())} ä¸ªå‚æ•°")\n",
    "\n",
    "# é€šçŸ¥Dashboardæ¨¡å‹åˆå§‹åŒ–å®Œæˆ\n",
    "try:\n",
    "    requests.post(f"{DASHBOARD_URL}/api/training/colab/status/{SESSION_ID}", \n",
    "                 json={"status": "model_ready", "model_type": model_type})\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start_training"
   },
   "outputs": [],
   "source": [
    "# ğŸš€ å¼€å§‹è®­ç»ƒ\n",
    "print("ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")\n",
    "print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")\n",
    "\n",
    "# è®­ç»ƒå‚æ•°\n",
    "train_args = {\n",
    "    "data": os.path.join(dataset.location, "data.yaml"),\n",
    "    "epochs": TRAINING_CONFIG["epochs"],\n",
    "    "batch": TRAINING_CONFIG["batch_size"],\n",
    "    "imgsz": TRAINING_CONFIG["img_size"],\n",
    "    "lr0": TRAINING_CONFIG["learning_rate"],\n",
    "    "patience": TRAINING_CONFIG["patience"],\n",
    "    "save_period": TRAINING_CONFIG["save_period"],\n",
    "    "project": OUTPUT_DIR,\n",
    "    "name": f"malaysian_food_{model_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",\n",
    "    "exist_ok": True,\n",
    "    "device": 0,  # ä½¿ç”¨GPU\n",
    "    "workers": 4,\n",
    "    "verbose": True\n",
    "}\n",
    "\n",
    "# é€šçŸ¥Dashboardå¼€å§‹è®­ç»ƒ\n",
    "try:\n",
    "    requests.post(f"{DASHBOARD_URL}/api/training/colab/status/{SESSION_ID}", \n",
    "                 json={"status": "training_started", "config": TRAINING_CONFIG})\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# å¼€å§‹è®­ç»ƒ\n",
    "results = model.train(**train_args)\n",
    "\n",
    "print("âœ… è®­ç»ƒå®Œæˆï¼")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_validation"
   },
   "outputs": [],
   "source": [
    "# ğŸ” æ¨¡å‹éªŒè¯\n",
    "print("ğŸ” æ¨¡å‹éªŒè¯...")\n",
    "best_model_path = os.path.join(results.save_dir, "weights", "best.pt")\n",
    "best_model = YOLO(best_model_path)\n",
    "\n",
    "# åœ¨éªŒè¯é›†ä¸ŠéªŒè¯\n",
    "val_results = best_model.val(data=os.path.join(dataset.location, "data.yaml"))\n",
    "\n",
    "print("âœ… æ¨¡å‹éªŒè¯å®Œæˆï¼")\n",
    "print(f"ğŸ“Š éªŒè¯ç»“æœ: {val_results}")\n",
    "\n",
    "# æå–å…³é”®æŒ‡æ ‡\n",
    "metrics = {\n",
    "    "accuracy": float(val_results.box.map) if hasattr(val_results.box, 'map') else 0.0,\n",
    "    "loss": float(val_results.box.map50) if hasattr(val_results.box, 'map50') else 0.0,\n",
    "    "precision": float(val_results.box.mp) if hasattr(val_results.box, 'mp') else 0.0,\n",
    "    "recall": float(val_results.box.mr) if hasattr(val_results.box, 'mr') else 0.0\n",
    "}\n",
    "\n",
    "# é€šçŸ¥DashboardéªŒè¯å®Œæˆ\n",
    "try:\n",
    "    requests.post(f"{DASHBOARD_URL}/api/training/colab/status/{SESSION_ID}", \n",
    "                 json={"status": "validation_completed", "metrics": metrics})\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nutrition_analysis"
   },
   "outputs": [],
   "source": [
    "# ğŸ§  Gemini AIè¥å…»åˆ†æé›†æˆ\n",
    "print("ğŸ§  é…ç½®Gemini AI...")\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model_gemini = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "def analyze_food_nutrition(food_name):\n",
    "    """ä½¿ç”¨Geminiåˆ†æé£Ÿç‰©è¥å…»ä¿¡æ¯"""\n",
    "    prompt = f"""\n",
    "    è¯·åˆ†æä»¥ä¸‹é©¬æ¥è¥¿äºšé£Ÿç‰©çš„è¥å…»ä¿¡æ¯ï¼š{food_name}\n",
    "    \n",
    "    è¯·æä¾›ï¼š\n",
    "    1. ä¸»è¦è¥å…»æˆåˆ†ï¼ˆå¡è·¯é‡Œã€è›‹ç™½è´¨ã€ç¢³æ°´åŒ–åˆç‰©ã€è„‚è‚ªï¼‰\n",
    "    2. ç»´ç”Ÿç´ å’ŒçŸ¿ç‰©è´¨å«é‡\n",
    "    3. å¥åº·å»ºè®®\n",
    "    4. é€‚åˆçš„é£Ÿç”¨æ—¶é—´\n",
    "    \n",
    "    è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œæ ¼å¼æ¸…æ™°ã€‚\n",
    "    """\n",
    "    \n",
    "    try:\n",
    "        response = model_gemini.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f"è¥å…»åˆ†æå¤±è´¥: {str(e)}"\n",
    "\n",
    "print("âœ… Gemini AIé…ç½®å®Œæˆï¼")\n",
    "\n",
    "# æµ‹è¯•è¥å…»åˆ†æ\n",
    "test_foods = ["Nasi Lemak", "Roti Canai", "Char Kway Teow", "Bak Kut Teh"]\n",
    "nutrition_results = {}\n",
    "\n",
    "print("ğŸœ é©¬æ¥è¥¿äºšé£Ÿç‰©è¥å…»åˆ†æ:")\n",
    "print("=" * 50)\n",
    "\n",
    "for food in test_foods:\n",
    "    print(f"\\nğŸ“Š åˆ†æé£Ÿç‰©: {food}")\n",
    "    nutrition_info = analyze_food_nutrition(food)\n",
    "    nutrition_results[food] = nutrition_info\n",
    "    print(nutrition_info)\n",
    "    print("-" * 30)\n",
    "\n",
    "# é€šçŸ¥Dashboardè¥å…»åˆ†æå®Œæˆ\n",
    "try:\n",
    "    requests.post(f"{DASHBOARD_URL}/api/training/colab/status/{SESSION_ID}", \n",
    "                 json={"status": "nutrition_analysis_completed", "nutrition_results": nutrition_results})\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_models"
   },
   "outputs": [],
   "source": [
    "# ğŸ“¦ å¯¼å‡ºæ¨¡å‹\n",
    "print("ğŸ“¦ å¯¼å‡ºæ¨¡å‹...")\n",
    "export_formats = ['onnx', 'torchscript']\n",
    "exported_models = {}\n",
    "\n",
    "for fmt in export_formats:\n",
    "    try:\n",
    "        print(f"ğŸ“¦ å¯¼å‡ºæ¨¡å‹æ ¼å¼: {fmt.upper()}")\n",
    "        exported_path = best_model.export(format=fmt)\n",
    "        exported_models[fmt] = exported_path\n",
    "        print(f"âœ… {fmt.upper()} æ¨¡å‹å¯¼å‡ºæˆåŠŸ: {exported_path}")\n",
    "    except Exception as e:\n",
    "        print(f"âŒ {fmt.upper()} æ¨¡å‹å¯¼å‡ºå¤±è´¥: {str(e)}")\n",
    "\n",
    "# é€šçŸ¥Dashboardæ¨¡å‹å¯¼å‡ºå®Œæˆ\n",
    "try:\n",
    "    requests.post(f"{DASHBOARD_URL}/api/training/colab/status/{SESSION_ID}", \n",
    "                 json={"status": "models_exported", "exported_models": exported_models})\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_summary"
   },
   "outputs": [],
   "source": [
    "# ğŸ“‹ è®­ç»ƒæ€»ç»“\n",
    "summary = {\n",
    "    "project_info": {\n",
    "        "name": "NutriScan MY - Malaysian Food Detection",\n",
    "        "project_id": ROBOFLOW_PROJECT_ID,\n",
    "        "model_type": model_type,\n",
    "        "session_id": SESSION_ID,\n",
    "        "training_date": datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    },\n",
    "    "training_config": TRAINING_CONFIG,\n",
    "    "dataset_info": dataset_stats,\n",
    "    "model_results": {\n",
    "        "best_model_path": best_model_path,\n",
    "        "exported_models": exported_models,\n",
    "        "validation_results": str(val_results),\n",
    "        "metrics": metrics\n",
    "    },\n",
    "    "nutrition_analysis": nutrition_results,\n",
    "    "api_integration": {\n",
    "        "roboflow_connected": True,\n",
    "        "gemini_configured": True,\n",
    "        "nutrition_analysis_ready": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# ä¿å­˜æ€»ç»“æŠ¥å‘Š\n",
    "summary_path = os.path.join(OUTPUT_DIR, "training_summary.json")\n",
    "with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print("\\nğŸ“‹ è®­ç»ƒæ€»ç»“æŠ¥å‘Š:")\n",
    "print("=" * 50)\n",
    "print(f"é¡¹ç›®åç§°: {summary['project_info']['name']}")\n",
    "print(f"æ¨¡å‹ç±»å‹: {summary['project_info']['model_type']}")\n",
    "print(f"è®­ç»ƒæ—¶é—´: {summary['project_info']['training_date']}")\n",
    "print(f"æ•°æ®é›†å¤§å°: {summary['dataset_info']['total_images']} å¼ å›¾ç‰‡")\n",
    "print(f"æœ€ä½³æ¨¡å‹: {os.path.basename(best_model_path)}")\n",
    "print(f"å¯¼å‡ºæ ¼å¼: {', '.join(exported_models.keys())}")\n",
    "print(f"\\nğŸ“ æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {OUTPUT_DIR}")\n",
    "print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {summary_path}")\n",
    "\n",
    "# æœ€ç»ˆé€šçŸ¥Dashboardè®­ç»ƒå®Œæˆ\n",
    "try:\n",
    "    requests.post(f"{DASHBOARD_URL}/api/training/colab/result", \n",
    "                 json={\n",
    "                     "session_id": SESSION_ID,\n",
    "                     "status": "completed",\n",
    "                     "summary": summary,\n",
    "                     "timestamp": datetime.now().isoformat()\n",
    "                 })\n",
    "    print("âœ… è®­ç»ƒç»“æœå·²åŒæ­¥åˆ°Dashboard")\n",
    "except:\n",
    "    print("âš ï¸ æ— æ³•åŒæ­¥ç»“æœåˆ°Dashboard")\n",
    "\n",
    "print("\\nğŸ‰ NutriScan MY æ¨¡å‹è®­ç»ƒå®Œæˆï¼")\n",
    "print("âœ… æ‚¨çš„é©¬æ¥è¥¿äºšé£Ÿç‰©è¯†åˆ«æ¨¡å‹å·²å‡†å¤‡å°±ç»ªï¼")\n",
    "print("ğŸš€ ç°åœ¨å¯ä»¥éƒ¨ç½²åˆ°ç§»åŠ¨ç«¯æˆ–Webåº”ç”¨ä¸­ä½¿ç”¨ï¼")\n",
    "print(f"\\nğŸ”— è¯·åœ¨Dashboardä¸­æŸ¥çœ‹è®­ç»ƒç»“æœ: {DASHBOARD_URL}/training")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}`;
    }
}

module.exports = ColabTemplateGenerator;
