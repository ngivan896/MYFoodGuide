/**
 * ğŸœ NutriScan MY - Google Colab æ¨¡æ¿ç”Ÿæˆå™¨ (ç®€åŒ–ç‰ˆ)
 * ç”Ÿæˆæ— JSONè¯­æ³•é”™è¯¯çš„è®­ç»ƒæ¨¡æ¿
 */

class ColabTemplateGenerator {
    constructor() {
        this.templateBase = this.getBaseTemplate();
    }

    /**
     * ç”ŸæˆåŒ…å«ç”¨æˆ·é…ç½®çš„Colabæ¨¡æ¿
     */
    generateTemplate(trainingConfig) {
        const config = {
            model_type: trainingConfig.model_type || 'yolov8n',
            epochs: trainingConfig.epochs || 100,
            batch_size: trainingConfig.batch_size || 16,
            learning_rate: trainingConfig.learning_rate || 0.01,
            img_size: trainingConfig.img_size || 640,
            patience: trainingConfig.patience || 20,
            save_period: trainingConfig.save_period || 10,
            session_id: trainingConfig.session_id || this.generateSessionId(),
            dashboard_url: trainingConfig.dashboard_url || 'http://localhost:5000',
            dataset_id: trainingConfig.dataset_id || 'default_dataset',
            augment: trainingConfig.augment || true,
            optimizer: trainingConfig.optimizer || 'AdamW',
            loss_function: trainingConfig.loss_function || 'BCE'
        };

        // æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´é»˜è®¤å‚æ•°
        if (config.model_type === 'yolov8s') {
            config.batch_size = Math.min(config.batch_size, 12);
            config.learning_rate = Math.min(config.learning_rate, 0.005);
        } else if (config.model_type === 'yolov8m') {
            config.batch_size = Math.min(config.batch_size, 8);
            config.learning_rate = Math.min(config.learning_rate, 0.003);
        }

        return this.templateBase
            .replace(/{{MODEL_TYPE}}/g, config.model_type)
            .replace(/{{EPOCHS}}/g, config.epochs)
            .replace(/{{BATCH_SIZE}}/g, config.batch_size)
            .replace(/{{LEARNING_RATE}}/g, config.learning_rate)
            .replace(/{{IMG_SIZE}}/g, config.img_size)
            .replace(/{{PATIENCE}}/g, config.patience)
            .replace(/{{SAVE_PERIOD}}/g, config.save_period)
            .replace(/{{SESSION_ID}}/g, config.session_id)
            .replace(/{{DASHBOARD_URL}}/g, config.dashboard_url)
            .replace(/{{DATASET_ID}}/g, config.dataset_id)
            .replace(/{{AUGMENT}}/g, config.augment ? 'True' : 'False')
            .replace(/{{OPTIMIZER}}/g, config.optimizer)
            .replace(/{{LOSS_FUNCTION}}/g, config.loss_function);
    }

    /**
     * ç”Ÿæˆä¼šè¯ID
     */
    generateSessionId() {
        return 'session_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
    }

    /**
     * è·å–åŸºç¡€æ¨¡æ¿ - ä½¿ç”¨ç®€åŒ–çš„JSONç»“æ„
     */
    getBaseTemplate() {
        return `{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nutriscan_header"
   },
   "source": [
    "# ğŸœ NutriScan MY - é©¬æ¥è¥¿äºšé£Ÿç‰©è¯†åˆ«æ¨¡å‹è®­ç»ƒ\\n",
    "\\n",
    "## ğŸ“‹ è®­ç»ƒé…ç½®\\n",
    "- **ä¼šè¯ID**: {{SESSION_ID}}\\n",
    "- **æ¨¡å‹ç±»å‹**: {{MODEL_TYPE}}\\n",
    "- **è®­ç»ƒè½®æ¬¡**: {{EPOCHS}}\\n",
    "- **æ‰¹æ¬¡å¤§å°**: {{BATCH_SIZE}}\\n",
    "- **å­¦ä¹ ç‡**: {{LEARNING_RATE}}\\n",
    "- **å›¾åƒå¤§å°**: {{IMG_SIZE}}\\n",
    "\\n",
    "---\\n",
    "\\n",
    "## ğŸš€ è‡ªåŠ¨é…ç½®å®Œæˆï¼Œç‚¹å‡»è¿è¡Œæ‰€æœ‰å•å…ƒæ ¼å¼€å§‹è®­ç»ƒï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# ğŸ”§ å®‰è£…ä¾èµ–åŒ…\\n",
    "!pip install ultralytics torch torchvision matplotlib seaborn pandas numpy requests --quiet\\n",
    "print('âœ… ä¾èµ–åŒ…å®‰è£…å®Œæˆï¼')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_libraries"
   },
   "outputs": [],
   "source": [
    "# ğŸ“š å¯¼å…¥åº“\\n",
    "import os\\n",
    "import json\\n",
    "import time\\n",
    "import requests\\n",
    "from datetime import datetime\\n",
    "import matplotlib.pyplot as plt\\n",
    "import seaborn as sns\\n",
    "import pandas as pd\\n",
    "import numpy as np\\n",
    "\\n",
    "# YOLOv8\\n",
    "from ultralytics import YOLO\\n",
    "\\n",
    "print('âœ… åº“å¯¼å…¥å®Œæˆï¼')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_parameters"
   },
   "outputs": [],
   "source": [
    "# âš™ï¸ é…ç½®å‚æ•° - æ¥è‡ªDashboard\\n",
    "SESSION_ID = '{{SESSION_ID}}'\\n",
    "DASHBOARD_URL = '{{DASHBOARD_URL}}'\\n",
    "\\n",
    "# è®­ç»ƒé…ç½® - ä»Dashboardä¼ é€’\\n",
    "TRAINING_CONFIG = {\\n",
    "    'model_type': '{{MODEL_TYPE}}',\\n",
    "    'epochs': {{EPOCHS}},\\n",
    "    'batch_size': {{BATCH_SIZE}},\\n",
    "    'learning_rate': {{LEARNING_RATE}},\\n",
    "    'img_size': {{IMG_SIZE}},\\n",
    "    'patience': {{PATIENCE}},\\n",
    "    'save_period': {{SAVE_PERIOD}},\\n",
    "    'augment': {{AUGMENT}},\\n",
    "    'optimizer': '{{OPTIMIZER}}',\\n",
    "    'loss_function': '{{LOSS_FUNCTION}}'\\n",
    "}\\n",
    "\\n",
    "# è¾“å‡ºç›®å½•\\n",
    "OUTPUT_DIR = f'/content/nutriscan_training_{SESSION_ID}'\\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\\n",
    "\\n",
    "print('âœ… é…ç½®å‚æ•°è®¾ç½®å®Œæˆï¼')\\n",
    "print(f'ğŸ“Š è®­ç»ƒé…ç½®: {TRAINING_CONFIG}')\\n",
    "print(f'ğŸ†” ä¼šè¯ID: {SESSION_ID}')\\n",
    "print(f'ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}')\\n",
    "\\n",
    "# é€šçŸ¥Dashboardè®­ç»ƒå¼€å§‹\\n",
    "try:\\n",
    "    requests.post(f'{DASHBOARD_URL}/api/training/colab/status/{SESSION_ID}', \\n",
    "                 json={'status': 'started', 'timestamp': datetime.now().isoformat(), 'config': TRAINING_CONFIG})\\n",
    "    print('âœ… å·²é€šçŸ¥Dashboardè®­ç»ƒå¼€å§‹')\\n",
    "except:\\n",
    "    print('âš ï¸ æ— æ³•è¿æ¥åˆ°Dashboardï¼Œç»§ç»­è®­ç»ƒ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_roboflow_dataset"
   },
   "outputs": [],
   "source": [
    "# ğŸ“Š ä»Roboflowä¸‹è½½é©¬æ¥è¥¿äºšé£Ÿç‰©æ•°æ®é›†\\n",
    "print('ğŸ”— ä»Roboflowä¸‹è½½é©¬æ¥è¥¿äºšé£Ÿç‰©æ•°æ®é›†...')\\n",
    "\\n",
    "# å®‰è£…Roboflow\\n",
    "!pip install roboflow --quiet\\n",
    "\\n",
    "# å¯¼å…¥Roboflow\\n",
    "from roboflow import Roboflow\\n",
    "\\n",
    "# Roboflowé…ç½® - ä½¿ç”¨æ­£ç¡®çš„é¡¹ç›®ä¿¡æ¯\\n",
    "ROBOFLOW_API_KEY = 'BwTemPbP39LHLFH4teds'\\n",
    "ROBOFLOW_PROJECT_ID = 'malaysian-food-detection-wy3kt'\\n",
    "ROBOFLOW_WORKSPACE = 'malaysian-food-detection'\\n",
    "\\n",
    "print('ğŸ”— è¿æ¥åˆ°Roboflowé¡¹ç›®...')\\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\\n",
    "project = rf.workspace(ROBOFLOW_WORKSPACE).project(ROBOFLOW_PROJECT_ID)\\n",
    "\\n",
    "# æ£€æŸ¥é¡¹ç›®ç‰ˆæœ¬\\n",
    "print('ğŸ“‹ æ£€æŸ¥é¡¹ç›®ç‰ˆæœ¬...')\\n",
    "try:\\n",
    "    versions = project.list_versions()\\n",
    "    print(f'å¯ç”¨ç‰ˆæœ¬: {versions}')\\n",
    "    \\n",
    "    # ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬\\n",
    "    if versions and len(versions) > 0:\\n",
    "        # è·å–ç‰ˆæœ¬å·ï¼ˆä»idä¸­æå–æ•°å­—ï¼‰\\n",
    "        version_numbers = []\\n",
    "        for v in versions:\\n",
    "            if 'id' in v:\\n",
    "                version_id = v['id']\\n",
    "                # æå–ç‰ˆæœ¬å·ï¼Œä¾‹å¦‚ä» 'malaysian-food-detection/malaysian-food-detection-wy3kt/2' æå– '2'\\n",
    "                if '/' in version_id:\\n",
    "                    version_num = version_id.split('/')[-1]\\n",
    "                    try:\\n",
    "                        version_numbers.append(int(version_num))\\n",
    "                    except ValueError:\\n",
    "                        continue\\n",
    "        \\n",
    "        if version_numbers:\\n",
    "            version_number = max(version_numbers)\\n",
    "            print(f'ä½¿ç”¨ç‰ˆæœ¬: {version_number}')\\n",
    "        else:\\n",
    "            print('âš ï¸ æ— æ³•è§£æç‰ˆæœ¬å·ï¼Œå°è¯•ä½¿ç”¨ç‰ˆæœ¬2')\\n",
    "            version_number = 2\\n",
    "    else:\\n",
    "        print('âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç‰ˆæœ¬ï¼Œå°è¯•ä½¿ç”¨ç‰ˆæœ¬2')\\n",
    "        version_number = 2\\n",
    "except Exception as e:\\n",
    "    print(f'âš ï¸ ç‰ˆæœ¬æ£€æŸ¥å¤±è´¥: {str(e)}')\\n",
    "    print('ä½¿ç”¨é»˜è®¤ç‰ˆæœ¬2')\\n",
    "    version_number = 2\\n",
    "\\n",
    "print('ğŸ“¥ ä¸‹è½½æ•°æ®é›†...')\\n",
    "try:\\n",
    "    dataset = project.version(version_number).download('yolov8')\\n",
    "    print(f'âœ… æ•°æ®é›†ä¸‹è½½å®Œæˆï¼')\\n",
    "    print(f'ğŸ“ æ•°æ®é›†è·¯å¾„: {dataset.location}')\\n",
    "except Exception as e:\\n",
    "    print(f'âŒ ä¸‹è½½å¤±è´¥: {str(e)}')\\n",
    "    print('\\nğŸ’¡ è¯·æ£€æŸ¥ä»¥ä¸‹å†…å®¹:')\\n",
    "    print('1. Roboflowé¡¹ç›®IDæ˜¯å¦æ­£ç¡®')\\n",
    "    print('2. APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ')\\n",
    "    print('3. é¡¹ç›®æ˜¯å¦æœ‰å¯ç”¨çš„ç‰ˆæœ¬')\\n",
    "    print('4. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸')\\n",
    "    raise e\\n",
    "\\n",
    "# ç»Ÿè®¡æ•°æ®é›†\\n",
    "def count_files(directory):\\n",
    "    if os.path.exists(directory):\\n",
    "        images = len([f for f in os.listdir(directory) if f.endswith(('.jpg', '.jpeg', '.png'))])\\n",
    "        labels = len([f for f in os.listdir(directory) if f.endswith('.txt')])\\n",
    "        return images, labels\\n",
    "    return 0, 0\\n",
    "\\n",
    "train_path = os.path.join(dataset.location, 'train')\\n",
    "val_path = os.path.join(dataset.location, 'valid')\\n",
    "test_path = os.path.join(dataset.location, 'test')\\n",
    "\\n",
    "train_images, train_labels = count_files(train_path)\\n",
    "val_images, val_labels = count_files(val_path)\\n",
    "test_images, test_labels = count_files(test_path)\\n",
    "\\n",
    "dataset_stats = {\\n",
    "    'train_images': train_images,\\n",
    "    'val_images': val_images,\\n",
    "    'test_images': test_images,\\n",
    "    'total_images': train_images + val_images + test_images,\\n",
    "    'dataset_path': dataset.location,\\n",
    "    'source': 'roboflow',\\n",
    "    'version': version_number\\n",
    "}\\n",
    "\\n",
    "print('\\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:')\\n",
    "print(f'  è®­ç»ƒé›†: {train_images} å¼ å›¾ç‰‡, {train_labels} ä¸ªæ ‡ç­¾æ–‡ä»¶')\\n",
    "print(f'  éªŒè¯é›†: {val_images} å¼ å›¾ç‰‡, {val_labels} ä¸ªæ ‡ç­¾æ–‡ä»¶')\\n",
    "print(f'  æµ‹è¯•é›†: {test_images} å¼ å›¾ç‰‡, {test_labels} ä¸ªæ ‡ç­¾æ–‡ä»¶')\\n",
    "print(f'  æ€»è®¡: {dataset_stats[\\\"total_images\\\"]} å¼ å›¾ç‰‡')\\n",
    "print(f'  æ¥æº: Roboflow (ä¸“ä¸šæ ‡æ³¨)')\\n",
    "print(f'  é¡¹ç›®: {ROBOFLOW_PROJECT_ID}')\\n",
    "print(f'  ç‰ˆæœ¬: {version_number}')\\n",
    "\\n",
    "# é€šçŸ¥Dashboardæ•°æ®é›†ä¿¡æ¯\\n",
    "try:\\n",
    "    requests.post(f'{DASHBOARD_URL}/api/training/colab/status/{SESSION_ID}', \\n",
    "                 json={'status': 'dataset_ready', 'dataset_stats': dataset_stats})\\n",
    "except:\\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "initialize_model"
   },
   "outputs": [],
   "source": [
    "# ğŸ¤– åˆå§‹åŒ–YOLOv8æ¨¡å‹\\n",
    "print('ğŸ¤– åˆå§‹åŒ–YOLOv8æ¨¡å‹...')\\n",
    "model_type = TRAINING_CONFIG['model_type']\\n",
    "model = YOLO(f'{model_type}.pt')\\n",
    "\\n",
    "print(f'âœ… YOLOv8æ¨¡å‹åˆå§‹åŒ–å®Œæˆ: {model_type}')\\n",
    "print(f'ğŸ“Š æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.model.parameters())} ä¸ªå‚æ•°')\\n",
    "\\n",
    "# é€šçŸ¥Dashboardæ¨¡å‹åˆå§‹åŒ–å®Œæˆ\\n",
    "try:\\n",
    "    requests.post(f'{DASHBOARD_URL}/api/training/colab/status/{SESSION_ID}', \\n",
    "                 json={'status': 'model_ready', 'model_type': model_type})\\n",
    "except:\\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start_training"
   },
   "outputs": [],
   "source": [
    "# ğŸš€ å¼€å§‹è®­ç»ƒ\\n",
    "print('ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...')\\n",
    "print(f'â° å¼€å§‹æ—¶é—´: {datetime.now().strftime(\\\"%Y-%m-%d %H:%M:%S\\\")}')\\n",
    "\\n",
    "# è®­ç»ƒå‚æ•°\\n",
    "train_args = {\\n",
    "    'data': os.path.join(dataset.location, 'data.yaml'),\\n",
    "    'epochs': TRAINING_CONFIG['epochs'],\\n",
    "    'batch': TRAINING_CONFIG['batch_size'],\\n",
    "    'imgsz': TRAINING_CONFIG['img_size'],\\n",
    "    'lr0': TRAINING_CONFIG['learning_rate'],\\n",
    "    'patience': TRAINING_CONFIG['patience'],\\n",
    "    'save_period': TRAINING_CONFIG['save_period'],\\n",
    "    'project': OUTPUT_DIR,\\n",
    "    'name': f'malaysian_food_{model_type}_{datetime.now().strftime(\\\"%Y%m%d_%H%M%S\\\")}',\\n",
    "    'exist_ok': True,\\n",
    "    'device': 0,\\n",
    "    'workers': 4,\\n",
    "    'verbose': True\\n",
    "}\\n",
    "\\n",
    "# é€šçŸ¥Dashboardå¼€å§‹è®­ç»ƒ\\n",
    "try:\\n",
    "    requests.post(f'{DASHBOARD_URL}/api/training/colab/status/{SESSION_ID}', \\n",
    "                 json={'status': 'training_started', 'config': TRAINING_CONFIG})\\n",
    "except:\\n",
    "    pass\\n",
    "\\n",
    "# å¼€å§‹è®­ç»ƒ\\n",
    "results = model.train(**train_args)\\n",
    "\\n",
    "print('âœ… è®­ç»ƒå®Œæˆï¼')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_validation"
   },
   "outputs": [],
   "source": [
    "# ğŸ” æ¨¡å‹éªŒè¯\\n",
    "print('ğŸ” æ¨¡å‹éªŒè¯...')\\n",
    "best_model_path = os.path.join(results.save_dir, 'weights', 'best.pt')\\n",
    "best_model = YOLO(best_model_path)\\n",
    "\\n",
    "# åœ¨éªŒè¯é›†ä¸ŠéªŒè¯\\n",
    "val_results = best_model.val(data=os.path.join(dataset.location, 'data.yaml'))\\n",
    "\\n",
    "print('âœ… æ¨¡å‹éªŒè¯å®Œæˆï¼')\\n",
    "print(f'ğŸ“Š éªŒè¯ç»“æœ: {val_results}')\\n",
    "\\n",
    "# æå–å…³é”®æŒ‡æ ‡\\n",
    "metrics = {\\n",
    "    'accuracy': float(val_results.box.map) if hasattr(val_results.box, 'map') else 0.0,\\n",
    "    'loss': float(val_results.box.map50) if hasattr(val_results.box, 'map50') else 0.0,\\n",
    "    'precision': float(val_results.box.mp) if hasattr(val_results.box, 'mp') else 0.0,\\n",
    "    'recall': float(val_results.box.mr) if hasattr(val_results.box, 'mr') else 0.0\\n",
    "}\\n",
    "\\n",
    "# é€šçŸ¥DashboardéªŒè¯å®Œæˆ\\n",
    "try:\\n",
    "    requests.post(f'{DASHBOARD_URL}/api/training/colab/status/{SESSION_ID}', \\n",
    "                 json={'status': 'validation_completed', 'metrics': metrics})\\n",
    "except:\\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_models"
   },
   "outputs": [],
   "source": [
    "# ğŸ“¦ å¯¼å‡ºæ¨¡å‹\\n",
    "print('ğŸ“¦ å¯¼å‡ºæ¨¡å‹...')\\n",
    "export_formats = ['onnx', 'torchscript']\\n",
    "exported_models = {}\\n",
    "\\n",
    "for fmt in export_formats:\\n",
    "    try:\\n",
    "        print(f'ğŸ“¦ å¯¼å‡ºæ¨¡å‹æ ¼å¼: {fmt.upper()}')\\n",
    "        exported_path = best_model.export(format=fmt)\\n",
    "        exported_models[fmt] = exported_path\\n",
    "        print(f'âœ… {fmt.upper()} æ¨¡å‹å¯¼å‡ºæˆåŠŸ: {exported_path}')\\n",
    "    except Exception as e:\\n",
    "        print(f'âŒ {fmt.upper()} æ¨¡å‹å¯¼å‡ºå¤±è´¥: {str(e)}')\\n",
    "\\n",
    "# é€šçŸ¥Dashboardæ¨¡å‹å¯¼å‡ºå®Œæˆ\\n",
    "try:\\n",
    "    requests.post(f'{DASHBOARD_URL}/api/training/colab/status/{SESSION_ID}', \\n",
    "                 json={'status': 'models_exported', 'exported_models': exported_models})\\n",
    "except:\\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_summary"
   },
   "outputs": [],
   "source": [
    "# ğŸ“‹ è®­ç»ƒæ€»ç»“\\n",
    "summary = {\\n",
    "    'project_info': {\\n",
    "        'name': 'NutriScan MY - Malaysian Food Detection',\\n",
    "        'model_type': model_type,\\n",
    "        'session_id': SESSION_ID,\\n",
    "        'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\\n",
    "    },\\n",
    "    'training_config': TRAINING_CONFIG,\\n",
    "    'dataset_info': dataset_stats,\\n",
    "    'model_results': {\\n",
    "        'best_model_path': best_model_path,\\n",
    "        'exported_models': exported_models,\\n",
    "        'validation_results': str(val_results),\\n",
    "        'metrics': metrics\\n",
    "    }\\n",
    "}\\n",
    "\\n",
    "# ä¿å­˜æ€»ç»“æŠ¥å‘Š\\n",
    "summary_path = os.path.join(OUTPUT_DIR, 'training_summary.json')\\n",
    "with open(summary_path, 'w', encoding='utf-8') as f:\\n",
    "    json.dump(summary, f, indent=2, ensure_ascii=False)\\n",
    "\\n",
    "print('\\nğŸ“‹ è®­ç»ƒæ€»ç»“æŠ¥å‘Š:')\\n",
    "print('=' * 50)\\n",
    "print(f'é¡¹ç›®åç§°: {summary[\\\"project_info\\\"][\\\"name\\\"]}')\\n",
    "print(f'æ¨¡å‹ç±»å‹: {summary[\\\"project_info\\\"][\\\"model_type\\\"]}')\\n",
    "print(f'è®­ç»ƒæ—¶é—´: {summary[\\\"project_info\\\"][\\\"training_date\\\"]}')\\n",
    "print(f'æ•°æ®é›†å¤§å°: {summary[\\\"dataset_info\\\"][\\\"total_images\\\"]} å¼ å›¾ç‰‡')\\n",
    "print(f'æœ€ä½³æ¨¡å‹: {os.path.basename(best_model_path)}')\\n",
    "print(f'å¯¼å‡ºæ ¼å¼: {\\\", \\\".join(exported_models.keys())}')\\n",
    "print(f'\\nğŸ“ æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {OUTPUT_DIR}')\\n",
    "print(f'ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {summary_path}')\\n",
    "\\n",
    "# æœ€ç»ˆé€šçŸ¥Dashboardè®­ç»ƒå®Œæˆ\\n",
    "try:\\n",
    "    requests.post(f'{DASHBOARD_URL}/api/training/colab/result', \\n",
    "                 json={\\n",
    "                     'session_id': SESSION_ID,\\n",
    "                     'status': 'completed',\\n",
    "                     'summary': summary,\\n",
    "                     'timestamp': datetime.now().isoformat()\\n",
    "                 })\\n",
    "    print('âœ… è®­ç»ƒç»“æœå·²åŒæ­¥åˆ°Dashboard')\\n",
    "except:\\n",
    "    print('âš ï¸ æ— æ³•åŒæ­¥ç»“æœåˆ°Dashboard')\\n",
    "\\n",
    "print('\\nğŸ‰ NutriScan MY æ¨¡å‹è®­ç»ƒå®Œæˆï¼')\\n",
    "print('âœ… æ‚¨çš„é©¬æ¥è¥¿äºšé£Ÿç‰©è¯†åˆ«æ¨¡å‹å·²å‡†å¤‡å°±ç»ªï¼')\\n",
    "print('ğŸš€ ç°åœ¨å¯ä»¥éƒ¨ç½²åˆ°ç§»åŠ¨ç«¯æˆ–Webåº”ç”¨ä¸­ä½¿ç”¨ï¼')\\n",
    "print(f'\\nğŸ”— è¯·åœ¨Dashboardä¸­æŸ¥çœ‹è®­ç»ƒç»“æœ: {DASHBOARD_URL}/training')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}`;
    }
}

module.exports = ColabTemplateGenerator;