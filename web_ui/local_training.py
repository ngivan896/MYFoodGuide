#!/usr/bin/env python3
"""
NutriScan MY - æœ¬åœ° YOLOv8 è®­ç»ƒè„šæœ¬
ä½¿ç”¨ Roboflow æ•°æ®é›† + Ultralytics API
"""

import os
import sys
from pathlib import Path
from ultralytics import YOLO
import yaml
import json
from datetime import datetime
import uuid

def download_roboflow_dataset():
    """ä» Roboflow ä¸‹è½½æ•°æ®é›†"""
    try:
        from roboflow import Roboflow
        
        print("ğŸ”— è¿æ¥åˆ° Roboflow...")
        rf = Roboflow(api_key="BwTemPbP39LHLFH4teds")
        project = rf.workspace("malaysian-food-detection").project("malaysian-food-detection-wy3kt")
        
        print("ğŸ“¥ ä¸‹è½½æ•°æ®é›†ç‰ˆæœ¬ 2...")
        dataset = project.version(2).download("yolov8")
        
        print(f"âœ… æ•°æ®é›†ä¸‹è½½å®Œæˆ: {dataset.location}")
        return dataset.location
        
    except Exception as e:
        print(f"âŒ Roboflow ä¸‹è½½å¤±è´¥: {e}")
        return None

def train_model(dataset_path, epochs=100, batch=16, imgsz=640):
    """è®­ç»ƒ YOLOv8 æ¨¡å‹"""
    
    # æ£€æŸ¥æ•°æ®é›†
    data_yaml = os.path.join(dataset_path, "data.yaml")
    if not os.path.exists(data_yaml):
        print(f"âŒ æ‰¾ä¸åˆ° data.yaml: {data_yaml}")
        return None
    
    print("ğŸ¤– åˆå§‹åŒ– YOLOv8 æ¨¡å‹...")
    model = YOLO('yolov8n.pt')  # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
    print(f"ğŸ“Š è®­ç»ƒå‚æ•°:")
    print(f"  - æ•°æ®é›†: {dataset_path}")
    print(f"  - è½®æ¬¡: {epochs}")
    print(f"  - æ‰¹æ¬¡å¤§å°: {batch}")
    print(f"  - å›¾åƒå°ºå¯¸: {imgsz}")
    
    # å¼€å§‹è®­ç»ƒ
    results = model.train(
        data=data_yaml,
        epochs=epochs,
        batch=batch,
        imgsz=imgsz,
        device='cpu',  # CPU (è‡ªåŠ¨å…¼å®¹æ— GPUç¯å¢ƒ)
        project='nutriscan_training',
        name=f'malaysian_food_yolov8n_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
        save=True,
        plots=True
    )
    
    print("âœ… è®­ç»ƒå®Œæˆ!")
    return model, results

def validate_model(model, dataset_path):
    """éªŒè¯æ¨¡å‹"""
    print("ğŸ” éªŒè¯æ¨¡å‹...")
    data_yaml = os.path.join(dataset_path, "data.yaml")
    results = model.val(data=data_yaml)
    print("âœ… éªŒè¯å®Œæˆ!")
    return results

def export_model(model):
    """å¯¼å‡ºæ¨¡å‹"""
    print("ğŸ“¦ å¯¼å‡ºæ¨¡å‹...")
    
    formats = ['onnx', 'torchscript', 'tflite']
    exported = {}
    
    for fmt in formats:
        try:
            path = model.export(format=fmt)
            exported[fmt] = path
            print(f"âœ… {fmt.upper()} å¯¼å‡ºæˆåŠŸ: {path}")
        except Exception as e:
            print(f"âŒ {fmt.upper()} å¯¼å‡ºå¤±è´¥: {e}")
    
    return exported

def save_training_session(training_info, session_file):
    os.makedirs(os.path.dirname(session_file), exist_ok=True)
    # åŠ è½½åŸæœ‰ä¼šè¯åˆ—è¡¨
    try:
        if os.path.exists(session_file):
            with open(session_file, 'r', encoding='utf-8') as f:
                sessions = json.load(f)
        else:
            sessions = {}
    except Exception:
        sessions = {}
    session_id = str(uuid.uuid4())
    now = datetime.now().isoformat()
    sessions[session_id] = {
        "id": session_id,
        "status": "completed",
        "created_at": now,
        "updated_at": now,
        "dataset_id": "roboflow_downloaded",
        "model_config": training_info.get("model_config", {}),
        "metrics": training_info.get("metrics", {}),
        "best_model_path": training_info.get("best_model_path", ""),
        "exported_models": training_info.get("exported_models", {}),
        "validation_results": training_info.get("validation_results", ""),
    }
    with open(session_file, 'w', encoding='utf-8') as f:
        json.dump(sessions, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“œ ä¼šè¯è®°å½•å·²åŒæ­¥åˆ°: {session_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ NutriScan MY - æœ¬åœ°è®­ç»ƒå¼€å§‹")
    print("=" * 50)
    
    # 1. ä¸‹è½½æ•°æ®é›†
    dataset_path = download_roboflow_dataset()
    if not dataset_path:
        print("âŒ æ— æ³•ä¸‹è½½æ•°æ®é›†ï¼Œé€€å‡º")
        return
    
    # 2. è®­ç»ƒæ¨¡å‹
    model, results = train_model(dataset_path)
    if not model:
        print("âŒ è®­ç»ƒå¤±è´¥ï¼Œé€€å‡º")
        return
    
    # 3. éªŒè¯æ¨¡å‹
    val_results = validate_model(model, dataset_path)
    
    # 4. å¯¼å‡ºæ¨¡å‹
    exported_models = export_model(model)
    
    # 5. ä¿å­˜è®­ç»ƒä¿¡æ¯
    training_info = {
        "timestamp": datetime.now().isoformat(),
        "dataset_path": dataset_path,
        "model_path": model.ckpt_path,
        "validation_results": str(val_results),
        "exported_models": exported_models
    }
    
    with open("training_results.json", "w") as f:
        json.dump(training_info, f, indent=2)
    
    # å°è¯•æå–æ›´ä¸°å¯Œçš„è®­ç»ƒå‚æ•°å’Œå¯è§†åŒ–æŒ‡æ ‡
    best_model_path = ""
    try:
        if hasattr(model, "trainer") and hasattr(model.trainer, "best"):
            best_model_path = model.trainer.best
        elif hasattr(model, "best"):
            best_model_path = model.best
        elif hasattr(model, "ckpt_path"):
            best_model_path = model.ckpt_path
    except Exception:
        best_model_path = ""

    # è·å–å‡†ç¡®ç‡ç­‰è®­ç»ƒæŒ‡æ ‡  
    metric_info = {}
    try:
        metric_info = results.results_dict if hasattr(results, 'results_dict') else {}
    except Exception:
        pass
    # è·å–è®­ç»ƒè¶…å‚æ•°ï¼ˆå…¨éƒ¨çœŸå®å‚æ•°ä¼˜å…ˆï¼‰
    train_config = None
    try:
        train_config = model.trainer.args if hasattr(model, 'trainer') and hasattr(model.trainer, 'args') else None
    except Exception:
        train_config = None
    model_config = train_config if train_config else {
        "model_type": "yolov8n",
        "epochs": 100,
        "batch_size": 16,
        "learning_rate": 0.01,
        "img_size": 640
    }
    # ç”Ÿæˆå®Œæ•´è®­ç»ƒå†å²
    session_file_path = os.path.join("data", "training_sessions.json")
    save_training_session({
        "model_config": model_config,
        "metrics": metric_info,
        "best_model_path": str(best_model_path),
        "exported_models": exported_models,
        "validation_results": str(val_results)
    }, session_file_path)
    # ç«‹å³è¾“å‡ºè°ƒè¯•æ£€æŸ¥
    import json
    if os.path.exists(session_file_path):
        with open(session_file_path, 'r', encoding='utf-8') as f:
            sessions = json.load(f)
            print('å†™å…¥å†å²:', json.dumps(sessions, ensure_ascii=False, indent=2))

    print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {model.ckpt_path}")
    print(f"ğŸ“„ è®­ç»ƒä¿¡æ¯: training_results.json")
    print("ğŸš€ ç°åœ¨å¯ä»¥éƒ¨ç½²åˆ°ä½ çš„åº”ç”¨ä¸­äº†!")

if __name__ == "__main__":
    main()

