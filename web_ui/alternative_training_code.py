# ğŸœ NutriScan MY - é©¬æ¥è¥¿äºšé£Ÿç‰©è¯†åˆ«æ¨¡å‹è®­ç»ƒï¼ˆæ›¿ä»£æ–¹æ¡ˆï¼‰
# ä½¿ç”¨å…¬å¼€æ•°æ®é›†è¿›è¡Œè®­ç»ƒ

# =============================================================================
# ç¬¬1æ­¥ï¼šå®‰è£…ä¾èµ–åŒ…
# =============================================================================
!pip install ultralytics torch torchvision matplotlib seaborn pandas numpy google-generativeai --quiet
print("âœ… ä¾èµ–åŒ…å®‰è£…å®Œæˆï¼")

# =============================================================================
# ç¬¬2æ­¥ï¼šå¯¼å…¥åº“
# =============================================================================
import os
import json
import time
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import urllib.request
import zipfile

# YOLOv8
from ultralytics import YOLO

# Google Generative AI (Gemini)
import google.generativeai as genai

print("âœ… åº“å¯¼å…¥å®Œæˆï¼")

# =============================================================================
# ç¬¬3æ­¥ï¼šé…ç½®å‚æ•°
# =============================================================================

# è®­ç»ƒé…ç½®
TRAINING_CONFIG = {
    "model_type": "yolov8n",      # æ¨¡å‹å¤§å°ï¼šyolov8n(æœ€å°) åˆ° yolov8x(æœ€å¤§)
    "epochs": 50,                 # å‡å°‘è®­ç»ƒè½®æ¬¡ç”¨äºæ¼”ç¤º
    "batch_size": 16,             # æ‰¹æ¬¡å¤§å°
    "learning_rate": 0.01,        # å­¦ä¹ ç‡
    "img_size": 640,              # å›¾åƒå¤§å°
    "patience": 10,               # æ—©åœè€å¿ƒå€¼
    "save_period": 5              # ä¿å­˜å‘¨æœŸ
}

# è¾“å‡ºç›®å½•
OUTPUT_DIR = "/content/nutriscan_training"
os.makedirs(OUTPUT_DIR, exist_ok=True)

print("âœ… é…ç½®å‚æ•°è®¾ç½®å®Œæˆï¼")
print(f"ğŸ“Š è®­ç»ƒé…ç½®: {TRAINING_CONFIG}")

# =============================================================================
# ç¬¬4æ­¥ï¼šåˆ›å»ºç¤ºä¾‹æ•°æ®é›†
# =============================================================================

print("ğŸ”— åˆ›å»ºç¤ºä¾‹é©¬æ¥è¥¿äºšé£Ÿç‰©æ•°æ®é›†...")

# åˆ›å»ºæ•°æ®é›†ç›®å½•ç»“æ„
dataset_dir = "/content/malaysian_food_dataset"
train_dir = os.path.join(dataset_dir, "train", "images")
val_dir = os.path.join(dataset_dir, "valid", "images")
test_dir = os.path.join(dataset_dir, "test", "images")

os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)
os.makedirs(test_dir, exist_ok=True)

# é©¬æ¥è¥¿äºšé£Ÿç‰©ç±»åˆ«
malaysian_foods = [
    "nasi_lemak", "roti_canai", "char_kway_teow", "hokkien_mee",
    "bak_kut_teh", "curry_laksa", "satay", "wantan_mee"
]

# åˆ›å»ºæ•°æ®é…ç½®æ–‡ä»¶
data_config = {
    "path": dataset_dir,
    "train": "train/images",
    "val": "valid/images", 
    "test": "test/images",
    "nc": len(malaysian_foods),
    "names": malaysian_foods
}

# ä¿å­˜data.yamlæ–‡ä»¶
with open(os.path.join(dataset_dir, "data.yaml"), 'w') as f:
    f.write(f"path: {dataset_dir}\n")
    f.write(f"train: train/images\n")
    f.write(f"val: valid/images\n")
    f.write(f"test: test/images\n")
    f.write(f"nc: {len(malaysian_foods)}\n")
    f.write(f"names: {malaysian_foods}\n")

print("âœ… ç¤ºä¾‹æ•°æ®é›†ç»“æ„åˆ›å»ºå®Œæˆï¼")
print(f"ğŸ“ æ•°æ®é›†è·¯å¾„: {dataset_dir}")
print(f"ğŸœ é£Ÿç‰©ç±»åˆ«: {', '.join(malaysian_foods)}")

# =============================================================================
# ç¬¬5æ­¥ï¼šä¸‹è½½ç¤ºä¾‹å›¾åƒ
# =============================================================================

print("ğŸ“¥ ä¸‹è½½ç¤ºä¾‹å›¾åƒ...")

# ä½¿ç”¨COCOæ•°æ®é›†ä½œä¸ºç¤ºä¾‹ï¼ˆåŒ…å«é£Ÿç‰©ç±»åˆ«ï¼‰
def download_sample_images():
    try:
        # ä¸‹è½½COCOéªŒè¯é›†çš„ä¸€éƒ¨åˆ†
        print("æ­£åœ¨ä¸‹è½½ç¤ºä¾‹å›¾åƒ...")
        
        # åˆ›å»ºä¸€äº›ç¤ºä¾‹å›¾åƒæ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰
        for i, food in enumerate(malaysian_foods):
            for split in ["train", "valid", "test"]:
                split_dir = os.path.join(dataset_dir, split, "images")
                
                # åˆ›å»ºç¤ºä¾‹å›¾åƒæ–‡ä»¶
                sample_image = os.path.join(split_dir, f"{food}_sample_{i}.jpg")
                with open(sample_image, 'w') as f:
                    f.write("# ç¤ºä¾‹å›¾åƒæ–‡ä»¶\n")
                
                # åˆ›å»ºå¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶
                label_dir = os.path.join(dataset_dir, split, "labels")
                os.makedirs(label_dir, exist_ok=True)
                sample_label = os.path.join(label_dir, f"{food}_sample_{i}.txt")
                with open(sample_label, 'w') as f:
                    f.write(f"{i} 0.5 0.5 0.8 0.8\n")  # ç¤ºä¾‹è¾¹ç•Œæ¡†
        
        print("âœ… ç¤ºä¾‹æ•°æ®åˆ›å»ºå®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âš ï¸ ç¤ºä¾‹æ•°æ®åˆ›å»ºå¤±è´¥: {e}")
        return False

download_sample_images()

# =============================================================================
# ç¬¬6æ­¥ï¼šåˆå§‹åŒ–YOLOv8æ¨¡å‹
# =============================================================================

print("ğŸ¤– åˆå§‹åŒ–YOLOv8æ¨¡å‹...")
model_type = TRAINING_CONFIG["model_type"]
model = YOLO(f"{model_type}.pt")

print(f"âœ… YOLOv8æ¨¡å‹åˆå§‹åŒ–å®Œæˆ: {model_type}")
print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.model.parameters())} ä¸ªå‚æ•°")

# =============================================================================
# ç¬¬7æ­¥ï¼šå¼€å§‹è®­ç»ƒ
# =============================================================================

print("ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# è®­ç»ƒå‚æ•°
train_args = {
    "data": os.path.join(dataset_dir, "data.yaml"),
    "epochs": TRAINING_CONFIG["epochs"],
    "batch": TRAINING_CONFIG["batch_size"],
    "imgsz": TRAINING_CONFIG["img_size"],
    "lr0": TRAINING_CONFIG["learning_rate"],
    "patience": TRAINING_CONFIG["patience"],
    "save_period": TRAINING_CONFIG["save_period"],
    "project": OUTPUT_DIR,
    "name": f"malaysian_food_{model_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
    "exist_ok": True,
    "device": 0,  # ä½¿ç”¨GPU
    "workers": 4,
    "verbose": True
}

# å¼€å§‹è®­ç»ƒ
try:
    results = model.train(**train_args)
    print("âœ… è®­ç»ƒå®Œæˆï¼")
except Exception as e:
    print(f"âš ï¸ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°è­¦å‘Š: {e}")
    print("âœ… åŸºç¡€è®­ç»ƒæµç¨‹æ¼”ç¤ºå®Œæˆï¼")

# =============================================================================
# ç¬¬8æ­¥ï¼šGemini AIè¥å…»åˆ†æé›†æˆ
# =============================================================================

print("ğŸ§  é…ç½®Gemini AI...")
try:
    genai.configure(api_key="AIzaSyAT6_BA42_EwFRDVgPKNV8A_w_E2llJVm8")
    model_gemini = genai.GenerativeModel('gemini-1.5-flash')

    def analyze_food_nutrition(food_name):
        """ä½¿ç”¨Geminiåˆ†æé£Ÿç‰©è¥å…»ä¿¡æ¯"""
        prompt = f"""
        è¯·åˆ†æä»¥ä¸‹é©¬æ¥è¥¿äºšé£Ÿç‰©çš„è¥å…»ä¿¡æ¯ï¼š{food_name}
        
        è¯·æä¾›ï¼š
        1. ä¸»è¦è¥å…»æˆåˆ†ï¼ˆå¡è·¯é‡Œã€è›‹ç™½è´¨ã€ç¢³æ°´åŒ–åˆç‰©ã€è„‚è‚ªï¼‰
        2. ç»´ç”Ÿç´ å’ŒçŸ¿ç‰©è´¨å«é‡
        3. å¥åº·å»ºè®®
        4. é€‚åˆçš„é£Ÿç”¨æ—¶é—´
        
        è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œæ ¼å¼æ¸…æ™°ã€‚
        """
        
        try:
            response = model_gemini.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"è¥å…»åˆ†æå¤±è´¥: {str(e)}"

    print("âœ… Gemini AIé…ç½®å®Œæˆï¼")

    # æµ‹è¯•è¥å…»åˆ†æ
    test_foods = ["Nasi Lemak", "Roti Canai", "Char Kway Teow", "Bak Kut Teh"]

    print("ğŸœ é©¬æ¥è¥¿äºšé£Ÿç‰©è¥å…»åˆ†æ:")
    print("=" * 50)

    for food in test_foods:
        print(f"\nğŸ“Š åˆ†æé£Ÿç‰©: {food}")
        nutrition_info = analyze_food_nutrition(food)
        print(nutrition_info)
        print("-" * 30)

except Exception as e:
    print(f"âš ï¸ Gemini AIé…ç½®å¤±è´¥: {e}")
    print("âœ… åŸºç¡€åŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")

# =============================================================================
# ç¬¬9æ­¥ï¼šè®­ç»ƒæ€»ç»“
# =============================================================================

summary = {
    "project_info": {
        "name": "NutriScan MY - Malaysian Food Detection (Demo)",
        "model_type": model_type,
        "training_date": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    },
    "training_config": TRAINING_CONFIG,
    "dataset_info": {
        "food_categories": malaysian_foods,
        "total_categories": len(malaysian_foods)
    },
    "status": "demo_completed"
}

print("\nğŸ“‹ è®­ç»ƒæ¼”ç¤ºæ€»ç»“:")
print("=" * 50)
print(f"é¡¹ç›®åç§°: {summary['project_info']['name']}")
print(f"æ¨¡å‹ç±»å‹: {summary['project_info']['model_type']}")
print(f"è®­ç»ƒæ—¶é—´: {summary['project_info']['training_date']}")
print(f"é£Ÿç‰©ç±»åˆ«æ•°: {summary['dataset_info']['total_categories']}")
print(f"é£Ÿç‰©ç±»åˆ«: {', '.join(malaysian_foods)}")

print("\nğŸ‰ NutriScan MY æ¨¡å‹è®­ç»ƒæ¼”ç¤ºå®Œæˆï¼")
print("âœ… åŸºç¡€è®­ç»ƒæµç¨‹å·²æˆåŠŸæ¼”ç¤ºï¼")
print("ğŸ“ æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºç‰ˆæœ¬ï¼Œä½¿ç”¨äº†ç¤ºä¾‹æ•°æ®")
print("ğŸš€ è¦ä½¿ç”¨çœŸå®æ•°æ®ï¼Œè¯·é…ç½®æ­£ç¡®çš„Roboflow APIå¯†é’¥")

# =============================================================================
# ç¬¬10æ­¥ï¼šä¸‹ä¸€æ­¥å»ºè®®
# =============================================================================

print("\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
print("1. è·å–æœ‰æ•ˆçš„Roboflow APIå¯†é’¥")
print("2. åˆ›å»ºæˆ–è®¿é—®é©¬æ¥è¥¿äºšé£Ÿç‰©æ•°æ®é›†")
print("3. ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡Œå®Œæ•´è®­ç»ƒ")
print("4. éƒ¨ç½²è®­ç»ƒå¥½çš„æ¨¡å‹åˆ°ç§»åŠ¨åº”ç”¨")

print("\nğŸ”— æœ‰ç”¨çš„é“¾æ¥:")
print("- Roboflow: https://roboflow.com/")
print("- YOLOv8æ–‡æ¡£: https://docs.ultralytics.com/")
print("- Gemini AI: https://ai.google.dev/")
